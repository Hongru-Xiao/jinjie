2023-02-07 06:59:03,394 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /data/apps/cuda/11.6
NVCC: Cuda compilation tools, release 11.6, V11.6.112
GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)
PyTorch: 1.12.0+cu116
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.0+cu116
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.6
MMClassification: 0.25.0+
------------------------------------------------------------

2023-02-07 06:59:03,395 - mmcls - INFO - Distributed training: False
2023-02-07 06:59:03,529 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='ResNet_CIFAR',
        depth=101,
        num_stages=4,
        out_indices=(3, ),
        style='pytorch'),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=10,
        in_channels=2048,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0)))
load_from = '/data/run01/scz0atc/mmclass/mmclassification/configs/resnet18/resnet101_b16x8_cifar10_20210528-2d29e936.pth'
dataset_type = 'CIFAR10'
img_norm_cfg = dict(
    mean=[125.307, 122.961, 113.8575],
    std=[51.5865, 50.847, 51.255],
    to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150])
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
resume_from = None
workflow = [('train', 1)]
work_dir = 'work/resnet/resnet101_8xb16_cifar10'
gpu_ids = [0]

2023-02-07 06:59:03,531 - mmcls - INFO - Set random seed to 1026109588, deterministic: False
2023-02-07 06:59:03,815 - mmcls - INFO - initialize ResNet_CIFAR with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-07 06:59:04,089 - mmcls - INFO - initialize LinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.6.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.6.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.6.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.6.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.6.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.6.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.7.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.7.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.7.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.7.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.7.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.7.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.8.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.8.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.8.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.8.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.8.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.8.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.9.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.9.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.9.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.9.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.9.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.9.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.10.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.10.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.10.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.10.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.10.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.10.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.11.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.11.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.11.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.11.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.11.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.11.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.12.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.12.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.12.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.12.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.12.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.12.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.13.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.13.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.13.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.13.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.13.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.13.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.14.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.14.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.14.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.14.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.14.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.14.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.15.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.15.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.15.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.15.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.15.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.15.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.16.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.16.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.16.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.16.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.16.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.16.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.17.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.17.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.17.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.17.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.17.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.17.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.18.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.18.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.18.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.18.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.18.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.18.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.19.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.19.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.19.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.19.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.19.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.19.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.20.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.20.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.20.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.20.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.20.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.20.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.21.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.21.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.21.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.21.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.21.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.21.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.22.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.22.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.22.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.22.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.22.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.22.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([10, 2048]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([10]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-02-07 06:59:09,557 - mmcls - INFO - load checkpoint from local path: /data/run01/scz0atc/mmclass/mmclassification/configs/resnet18/resnet101_b16x8_cifar10_20210528-2d29e936.pth
2023-02-07 06:59:09,963 - mmcls - INFO - Start running, host: scz0atc@g0014, work_dir: /data/run01/scz0atc/mmclass/mmclassification/work/resnet/resnet101_8xb16_cifar10
2023-02-07 06:59:09,964 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-07 06:59:09,964 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2023-02-07 06:59:09,964 - mmcls - INFO - Checkpoints will be saved to /data/run01/scz0atc/mmclass/mmclassification/work/resnet/resnet101_8xb16_cifar10 by HardDiskBackend.
2023-02-07 06:59:21,777 - mmcls - INFO - Epoch [1][100/3125]	lr: 1.000e-01, eta: 20:29:47, time: 0.118, data_time: 0.027, memory: 1110, loss: 1.6050
2023-02-07 06:59:27,027 - mmcls - INFO - Epoch [1][200/3125]	lr: 1.000e-01, eta: 14:48:10, time: 0.053, data_time: 0.000, memory: 1110, loss: 2.1296
2023-02-07 06:59:32,273 - mmcls - INFO - Epoch [1][300/3125]	lr: 1.000e-01, eta: 12:54:05, time: 0.052, data_time: 0.000, memory: 1110, loss: 2.0137
2023-02-07 06:59:37,514 - mmcls - INFO - Epoch [1][400/3125]	lr: 1.000e-01, eta: 11:56:51, time: 0.052, data_time: 0.000, memory: 1110, loss: 2.0018
2023-02-07 06:59:42,753 - mmcls - INFO - Epoch [1][500/3125]	lr: 1.000e-01, eta: 11:22:26, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.9538
2023-02-07 06:59:47,995 - mmcls - INFO - Epoch [1][600/3125]	lr: 1.000e-01, eta: 10:59:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.8861
2023-02-07 06:59:53,137 - mmcls - INFO - Epoch [1][700/3125]	lr: 1.000e-01, eta: 10:41:39, time: 0.051, data_time: 0.000, memory: 1110, loss: 1.8851
2023-02-07 06:59:58,331 - mmcls - INFO - Epoch [1][800/3125]	lr: 1.000e-01, eta: 10:28:53, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.8427
2023-02-07 07:00:03,511 - mmcls - INFO - Epoch [1][900/3125]	lr: 1.000e-01, eta: 10:18:47, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.8304
2023-02-07 07:00:08,695 - mmcls - INFO - Epoch [1][1000/3125]	lr: 1.000e-01, eta: 10:10:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.7652
2023-02-07 07:00:13,904 - mmcls - INFO - Epoch [1][1100/3125]	lr: 1.000e-01, eta: 10:04:21, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.7939
2023-02-07 07:00:19,168 - mmcls - INFO - Epoch [1][1200/3125]	lr: 1.000e-01, eta: 9:59:30, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.6948
2023-02-07 07:00:24,441 - mmcls - INFO - Epoch [1][1300/3125]	lr: 1.000e-01, eta: 9:55:28, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.7374
2023-02-07 07:00:29,711 - mmcls - INFO - Epoch [1][1400/3125]	lr: 1.000e-01, eta: 9:51:58, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.6890
2023-02-07 07:00:34,981 - mmcls - INFO - Epoch [1][1500/3125]	lr: 1.000e-01, eta: 9:48:55, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.7179
2023-02-07 07:00:40,252 - mmcls - INFO - Epoch [1][1600/3125]	lr: 1.000e-01, eta: 9:46:15, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.6389
2023-02-07 07:00:45,503 - mmcls - INFO - Epoch [1][1700/3125]	lr: 1.000e-01, eta: 9:43:46, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.6059
2023-02-07 07:00:50,718 - mmcls - INFO - Epoch [1][1800/3125]	lr: 1.000e-01, eta: 9:41:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.5998
2023-02-07 07:00:55,900 - mmcls - INFO - Epoch [1][1900/3125]	lr: 1.000e-01, eta: 9:38:58, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.5652
2023-02-07 07:01:01,112 - mmcls - INFO - Epoch [1][2000/3125]	lr: 1.000e-01, eta: 9:36:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.5413
2023-02-07 07:01:06,356 - mmcls - INFO - Epoch [1][2100/3125]	lr: 1.000e-01, eta: 9:35:21, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.4493
2023-02-07 07:01:11,604 - mmcls - INFO - Epoch [1][2200/3125]	lr: 1.000e-01, eta: 9:33:52, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.4968
2023-02-07 07:01:16,855 - mmcls - INFO - Epoch [1][2300/3125]	lr: 1.000e-01, eta: 9:32:31, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.4855
2023-02-07 07:01:22,117 - mmcls - INFO - Epoch [1][2400/3125]	lr: 1.000e-01, eta: 9:31:19, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.4534
2023-02-07 07:01:27,373 - mmcls - INFO - Epoch [1][2500/3125]	lr: 1.000e-01, eta: 9:30:12, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.3762
2023-02-07 07:01:32,619 - mmcls - INFO - Epoch [1][2600/3125]	lr: 1.000e-01, eta: 9:29:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.4178
2023-02-07 07:01:37,868 - mmcls - INFO - Epoch [1][2700/3125]	lr: 1.000e-01, eta: 9:28:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.4056
2023-02-07 07:01:43,100 - mmcls - INFO - Epoch [1][2800/3125]	lr: 1.000e-01, eta: 9:27:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.3358
2023-02-07 07:01:48,366 - mmcls - INFO - Epoch [1][2900/3125]	lr: 1.000e-01, eta: 9:26:17, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.3601
2023-02-07 07:01:53,620 - mmcls - INFO - Epoch [1][3000/3125]	lr: 1.000e-01, eta: 9:25:28, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.3527
2023-02-07 07:01:58,871 - mmcls - INFO - Epoch [1][3100/3125]	lr: 1.000e-01, eta: 9:24:42, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.3855
2023-02-07 07:02:00,186 - mmcls - INFO - Saving checkpoint at 1 epochs
2023-02-07 07:02:10,154 - mmcls - INFO - Epoch(val) [1][625]	accuracy_top-1: 50.5100, accuracy_top-5: 93.9300
2023-02-07 07:02:17,368 - mmcls - INFO - Epoch [2][100/3125]	lr: 1.000e-01, eta: 9:25:52, time: 0.072, data_time: 0.020, memory: 1110, loss: 1.2441
2023-02-07 07:02:22,571 - mmcls - INFO - Epoch [2][200/3125]	lr: 1.000e-01, eta: 9:24:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2287
2023-02-07 07:02:27,772 - mmcls - INFO - Epoch [2][300/3125]	lr: 1.000e-01, eta: 9:24:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2566
2023-02-07 07:02:32,967 - mmcls - INFO - Epoch [2][400/3125]	lr: 1.000e-01, eta: 9:23:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2642
2023-02-07 07:02:38,157 - mmcls - INFO - Epoch [2][500/3125]	lr: 1.000e-01, eta: 9:22:30, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2283
2023-02-07 07:02:43,349 - mmcls - INFO - Epoch [2][600/3125]	lr: 1.000e-01, eta: 9:21:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.3014
2023-02-07 07:02:48,542 - mmcls - INFO - Epoch [2][700/3125]	lr: 1.000e-01, eta: 9:21:01, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2765
2023-02-07 07:02:53,742 - mmcls - INFO - Epoch [2][800/3125]	lr: 1.000e-01, eta: 9:20:21, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1428
2023-02-07 07:02:58,937 - mmcls - INFO - Epoch [2][900/3125]	lr: 1.000e-01, eta: 9:19:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2143
2023-02-07 07:03:04,145 - mmcls - INFO - Epoch [2][1000/3125]	lr: 1.000e-01, eta: 9:19:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2546
2023-02-07 07:03:09,369 - mmcls - INFO - Epoch [2][1100/3125]	lr: 1.000e-01, eta: 9:18:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1863
2023-02-07 07:03:14,580 - mmcls - INFO - Epoch [2][1200/3125]	lr: 1.000e-01, eta: 9:18:02, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1859
2023-02-07 07:03:19,817 - mmcls - INFO - Epoch [2][1300/3125]	lr: 1.000e-01, eta: 9:17:35, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.2100
2023-02-07 07:03:25,071 - mmcls - INFO - Epoch [2][1400/3125]	lr: 1.000e-01, eta: 9:17:10, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.1844
2023-02-07 07:03:30,265 - mmcls - INFO - Epoch [2][1500/3125]	lr: 1.000e-01, eta: 9:16:39, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1895
2023-02-07 07:03:35,451 - mmcls - INFO - Epoch [2][1600/3125]	lr: 1.000e-01, eta: 9:16:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1740
2023-02-07 07:03:40,639 - mmcls - INFO - Epoch [2][1700/3125]	lr: 1.000e-01, eta: 9:15:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1732
2023-02-07 07:03:45,831 - mmcls - INFO - Epoch [2][1800/3125]	lr: 1.000e-01, eta: 9:15:09, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1254
2023-02-07 07:03:51,025 - mmcls - INFO - Epoch [2][1900/3125]	lr: 1.000e-01, eta: 9:14:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1503
2023-02-07 07:03:56,225 - mmcls - INFO - Epoch [2][2000/3125]	lr: 1.000e-01, eta: 9:14:16, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1710
2023-02-07 07:04:01,420 - mmcls - INFO - Epoch [2][2100/3125]	lr: 1.000e-01, eta: 9:13:50, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1440
2023-02-07 07:04:06,622 - mmcls - INFO - Epoch [2][2200/3125]	lr: 1.000e-01, eta: 9:13:26, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1392
2023-02-07 07:04:11,822 - mmcls - INFO - Epoch [2][2300/3125]	lr: 1.000e-01, eta: 9:13:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1496
2023-02-07 07:04:17,018 - mmcls - INFO - Epoch [2][2400/3125]	lr: 1.000e-01, eta: 9:12:39, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1385
2023-02-07 07:04:22,213 - mmcls - INFO - Epoch [2][2500/3125]	lr: 1.000e-01, eta: 9:12:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1151
2023-02-07 07:04:27,407 - mmcls - INFO - Epoch [2][2600/3125]	lr: 1.000e-01, eta: 9:11:54, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.1185
2023-02-07 07:04:32,599 - mmcls - INFO - Epoch [2][2700/3125]	lr: 1.000e-01, eta: 9:11:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0456
2023-02-07 07:04:37,794 - mmcls - INFO - Epoch [2][2800/3125]	lr: 1.000e-01, eta: 9:11:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0841
2023-02-07 07:04:42,989 - mmcls - INFO - Epoch [2][2900/3125]	lr: 1.000e-01, eta: 9:10:51, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0627
2023-02-07 07:04:48,210 - mmcls - INFO - Epoch [2][3000/3125]	lr: 1.000e-01, eta: 9:10:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0828
2023-02-07 07:04:53,467 - mmcls - INFO - Epoch [2][3100/3125]	lr: 1.000e-01, eta: 9:10:20, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0992
2023-02-07 07:04:54,786 - mmcls - INFO - Saving checkpoint at 2 epochs
2023-02-07 07:05:04,731 - mmcls - INFO - Epoch(val) [2][625]	accuracy_top-1: 60.5000, accuracy_top-5: 96.5200
2023-02-07 07:05:12,026 - mmcls - INFO - Epoch [3][100/3125]	lr: 1.000e-01, eta: 9:11:14, time: 0.073, data_time: 0.020, memory: 1110, loss: 1.0702
2023-02-07 07:05:17,272 - mmcls - INFO - Epoch [3][200/3125]	lr: 1.000e-01, eta: 9:10:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0220
2023-02-07 07:05:22,542 - mmcls - INFO - Epoch [3][300/3125]	lr: 1.000e-01, eta: 9:10:47, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0483
2023-02-07 07:05:27,802 - mmcls - INFO - Epoch [3][400/3125]	lr: 1.000e-01, eta: 9:10:34, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0422
2023-02-07 07:05:33,059 - mmcls - INFO - Epoch [3][500/3125]	lr: 1.000e-01, eta: 9:10:21, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0335
2023-02-07 07:05:38,321 - mmcls - INFO - Epoch [3][600/3125]	lr: 1.000e-01, eta: 9:10:08, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0325
2023-02-07 07:05:43,513 - mmcls - INFO - Epoch [3][700/3125]	lr: 1.000e-01, eta: 9:09:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0269
2023-02-07 07:05:48,728 - mmcls - INFO - Epoch [3][800/3125]	lr: 1.000e-01, eta: 9:09:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0197
2023-02-07 07:05:53,949 - mmcls - INFO - Epoch [3][900/3125]	lr: 1.000e-01, eta: 9:09:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0544
2023-02-07 07:05:59,208 - mmcls - INFO - Epoch [3][1000/3125]	lr: 1.000e-01, eta: 9:09:06, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0326
2023-02-07 07:06:04,391 - mmcls - INFO - Epoch [3][1100/3125]	lr: 1.000e-01, eta: 9:08:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0151
2023-02-07 07:06:09,623 - mmcls - INFO - Epoch [3][1200/3125]	lr: 1.000e-01, eta: 9:08:35, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9757
2023-02-07 07:06:14,883 - mmcls - INFO - Epoch [3][1300/3125]	lr: 1.000e-01, eta: 9:08:24, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0262
2023-02-07 07:06:20,138 - mmcls - INFO - Epoch [3][1400/3125]	lr: 1.000e-01, eta: 9:08:12, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0166
2023-02-07 07:06:25,424 - mmcls - INFO - Epoch [3][1500/3125]	lr: 1.000e-01, eta: 9:08:04, time: 0.053, data_time: 0.000, memory: 1110, loss: 1.0264
2023-02-07 07:06:30,697 - mmcls - INFO - Epoch [3][1600/3125]	lr: 1.000e-01, eta: 9:07:54, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.9412
2023-02-07 07:06:35,909 - mmcls - INFO - Epoch [3][1700/3125]	lr: 1.000e-01, eta: 9:07:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9574
2023-02-07 07:06:41,120 - mmcls - INFO - Epoch [3][1800/3125]	lr: 1.000e-01, eta: 9:07:26, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9784
2023-02-07 07:06:46,315 - mmcls - INFO - Epoch [3][1900/3125]	lr: 1.000e-01, eta: 9:07:10, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9458
2023-02-07 07:06:51,510 - mmcls - INFO - Epoch [3][2000/3125]	lr: 1.000e-01, eta: 9:06:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9577
2023-02-07 07:06:56,704 - mmcls - INFO - Epoch [3][2100/3125]	lr: 1.000e-01, eta: 9:06:41, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9847
2023-02-07 07:07:01,895 - mmcls - INFO - Epoch [3][2200/3125]	lr: 1.000e-01, eta: 9:06:26, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0307
2023-02-07 07:07:07,087 - mmcls - INFO - Epoch [3][2300/3125]	lr: 1.000e-01, eta: 9:06:12, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9557
2023-02-07 07:07:12,280 - mmcls - INFO - Epoch [3][2400/3125]	lr: 1.000e-01, eta: 9:05:58, time: 0.052, data_time: 0.000, memory: 1110, loss: 1.0064
2023-02-07 07:07:17,475 - mmcls - INFO - Epoch [3][2500/3125]	lr: 1.000e-01, eta: 9:05:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9991
2023-02-07 07:07:22,726 - mmcls - INFO - Epoch [3][2600/3125]	lr: 1.000e-01, eta: 9:05:34, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.9445
2023-02-07 07:07:27,976 - mmcls - INFO - Epoch [3][2700/3125]	lr: 1.000e-01, eta: 9:05:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9534
2023-02-07 07:07:33,212 - mmcls - INFO - Epoch [3][2800/3125]	lr: 1.000e-01, eta: 9:05:14, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9723
2023-02-07 07:07:38,405 - mmcls - INFO - Epoch [3][2900/3125]	lr: 1.000e-01, eta: 9:05:01, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9813
2023-02-07 07:07:43,612 - mmcls - INFO - Epoch [3][3000/3125]	lr: 1.000e-01, eta: 9:04:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9455
2023-02-07 07:07:48,852 - mmcls - INFO - Epoch [3][3100/3125]	lr: 1.000e-01, eta: 9:04:39, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9187
2023-02-07 07:07:50,165 - mmcls - INFO - Saving checkpoint at 3 epochs
2023-02-07 07:08:00,112 - mmcls - INFO - Epoch(val) [3][625]	accuracy_top-1: 62.8900, accuracy_top-5: 97.4000
2023-02-07 07:08:07,362 - mmcls - INFO - Epoch [4][100/3125]	lr: 1.000e-01, eta: 9:05:12, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.9919
2023-02-07 07:08:12,562 - mmcls - INFO - Epoch [4][200/3125]	lr: 1.000e-01, eta: 9:04:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9088
2023-02-07 07:08:17,783 - mmcls - INFO - Epoch [4][300/3125]	lr: 1.000e-01, eta: 9:04:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9270
2023-02-07 07:08:23,002 - mmcls - INFO - Epoch [4][400/3125]	lr: 1.000e-01, eta: 9:04:37, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9213
2023-02-07 07:08:28,193 - mmcls - INFO - Epoch [4][500/3125]	lr: 1.000e-01, eta: 9:04:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9063
2023-02-07 07:08:33,391 - mmcls - INFO - Epoch [4][600/3125]	lr: 1.000e-01, eta: 9:04:12, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9432
2023-02-07 07:08:38,594 - mmcls - INFO - Epoch [4][700/3125]	lr: 1.000e-01, eta: 9:04:00, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8084
2023-02-07 07:08:43,796 - mmcls - INFO - Epoch [4][800/3125]	lr: 1.000e-01, eta: 9:03:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9278
2023-02-07 07:08:48,998 - mmcls - INFO - Epoch [4][900/3125]	lr: 1.000e-01, eta: 9:03:36, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9620
2023-02-07 07:08:54,197 - mmcls - INFO - Epoch [4][1000/3125]	lr: 1.000e-01, eta: 9:03:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9139
2023-02-07 07:08:59,399 - mmcls - INFO - Epoch [4][1100/3125]	lr: 1.000e-01, eta: 9:03:13, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9291
2023-02-07 07:09:04,596 - mmcls - INFO - Epoch [4][1200/3125]	lr: 1.000e-01, eta: 9:03:02, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8496
2023-02-07 07:09:09,786 - mmcls - INFO - Epoch [4][1300/3125]	lr: 1.000e-01, eta: 9:02:50, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9562
2023-02-07 07:09:14,980 - mmcls - INFO - Epoch [4][1400/3125]	lr: 1.000e-01, eta: 9:02:39, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8909
2023-02-07 07:09:20,173 - mmcls - INFO - Epoch [4][1500/3125]	lr: 1.000e-01, eta: 9:02:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9148
2023-02-07 07:09:25,384 - mmcls - INFO - Epoch [4][1600/3125]	lr: 1.000e-01, eta: 9:02:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8327
2023-02-07 07:09:30,584 - mmcls - INFO - Epoch [4][1700/3125]	lr: 1.000e-01, eta: 9:02:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9224
2023-02-07 07:09:35,785 - mmcls - INFO - Epoch [4][1800/3125]	lr: 1.000e-01, eta: 9:01:55, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8389
2023-02-07 07:09:40,981 - mmcls - INFO - Epoch [4][1900/3125]	lr: 1.000e-01, eta: 9:01:45, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8385
2023-02-07 07:09:46,180 - mmcls - INFO - Epoch [4][2000/3125]	lr: 1.000e-01, eta: 9:01:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8754
2023-02-07 07:09:51,391 - mmcls - INFO - Epoch [4][2100/3125]	lr: 1.000e-01, eta: 9:01:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8692
2023-02-07 07:09:56,610 - mmcls - INFO - Epoch [4][2200/3125]	lr: 1.000e-01, eta: 9:01:15, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9210
2023-02-07 07:10:01,832 - mmcls - INFO - Epoch [4][2300/3125]	lr: 1.000e-01, eta: 9:01:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8656
2023-02-07 07:10:07,043 - mmcls - INFO - Epoch [4][2400/3125]	lr: 1.000e-01, eta: 9:00:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8883
2023-02-07 07:10:12,259 - mmcls - INFO - Epoch [4][2500/3125]	lr: 1.000e-01, eta: 9:00:47, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8323
2023-02-07 07:10:17,465 - mmcls - INFO - Epoch [4][2600/3125]	lr: 1.000e-01, eta: 9:00:37, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.9026
2023-02-07 07:10:22,681 - mmcls - INFO - Epoch [4][2700/3125]	lr: 1.000e-01, eta: 9:00:28, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8490
2023-02-07 07:10:27,894 - mmcls - INFO - Epoch [4][2800/3125]	lr: 1.000e-01, eta: 9:00:19, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8266
2023-02-07 07:10:33,135 - mmcls - INFO - Epoch [4][2900/3125]	lr: 1.000e-01, eta: 9:00:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8404
2023-02-07 07:10:38,408 - mmcls - INFO - Epoch [4][3000/3125]	lr: 1.000e-01, eta: 9:00:05, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.9048
2023-02-07 07:10:43,673 - mmcls - INFO - Epoch [4][3100/3125]	lr: 1.000e-01, eta: 8:59:58, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8742
2023-02-07 07:10:44,987 - mmcls - INFO - Saving checkpoint at 4 epochs
2023-02-07 07:10:55,247 - mmcls - INFO - Epoch(val) [4][625]	accuracy_top-1: 73.5900, accuracy_top-5: 97.9300
2023-02-07 07:11:02,538 - mmcls - INFO - Epoch [5][100/3125]	lr: 1.000e-01, eta: 9:00:25, time: 0.073, data_time: 0.020, memory: 1110, loss: 0.8672
2023-02-07 07:11:07,799 - mmcls - INFO - Epoch [5][200/3125]	lr: 1.000e-01, eta: 9:00:18, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8546
2023-02-07 07:11:13,059 - mmcls - INFO - Epoch [5][300/3125]	lr: 1.000e-01, eta: 9:00:11, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8213
2023-02-07 07:11:18,321 - mmcls - INFO - Epoch [5][400/3125]	lr: 1.000e-01, eta: 9:00:04, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8075
2023-02-07 07:11:23,586 - mmcls - INFO - Epoch [5][500/3125]	lr: 1.000e-01, eta: 8:59:57, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8273
2023-02-07 07:11:28,852 - mmcls - INFO - Epoch [5][600/3125]	lr: 1.000e-01, eta: 8:59:51, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8065
2023-02-07 07:11:34,121 - mmcls - INFO - Epoch [5][700/3125]	lr: 1.000e-01, eta: 8:59:44, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8075
2023-02-07 07:11:39,385 - mmcls - INFO - Epoch [5][800/3125]	lr: 1.000e-01, eta: 8:59:38, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.8572
2023-02-07 07:11:44,653 - mmcls - INFO - Epoch [5][900/3125]	lr: 1.000e-01, eta: 8:59:31, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7914
2023-02-07 07:11:49,899 - mmcls - INFO - Epoch [5][1000/3125]	lr: 1.000e-01, eta: 8:59:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7650
2023-02-07 07:11:55,104 - mmcls - INFO - Epoch [5][1100/3125]	lr: 1.000e-01, eta: 8:59:14, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8035
2023-02-07 07:12:00,304 - mmcls - INFO - Epoch [5][1200/3125]	lr: 1.000e-01, eta: 8:59:05, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7545
2023-02-07 07:12:05,499 - mmcls - INFO - Epoch [5][1300/3125]	lr: 1.000e-01, eta: 8:58:55, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8220
2023-02-07 07:12:10,689 - mmcls - INFO - Epoch [5][1400/3125]	lr: 1.000e-01, eta: 8:58:46, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7553
2023-02-07 07:12:15,880 - mmcls - INFO - Epoch [5][1500/3125]	lr: 1.000e-01, eta: 8:58:36, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7930
2023-02-07 07:12:21,073 - mmcls - INFO - Epoch [5][1600/3125]	lr: 1.000e-01, eta: 8:58:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8507
2023-02-07 07:12:26,278 - mmcls - INFO - Epoch [5][1700/3125]	lr: 1.000e-01, eta: 8:58:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8428
2023-02-07 07:12:31,478 - mmcls - INFO - Epoch [5][1800/3125]	lr: 1.000e-01, eta: 8:58:09, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8603
2023-02-07 07:12:36,667 - mmcls - INFO - Epoch [5][1900/3125]	lr: 1.000e-01, eta: 8:57:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7504
2023-02-07 07:12:41,865 - mmcls - INFO - Epoch [5][2000/3125]	lr: 1.000e-01, eta: 8:57:50, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8162
2023-02-07 07:12:47,089 - mmcls - INFO - Epoch [5][2100/3125]	lr: 1.000e-01, eta: 8:57:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7796
2023-02-07 07:12:52,331 - mmcls - INFO - Epoch [5][2200/3125]	lr: 1.000e-01, eta: 8:57:35, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7521
2023-02-07 07:12:57,589 - mmcls - INFO - Epoch [5][2300/3125]	lr: 1.000e-01, eta: 8:57:29, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7656
2023-02-07 07:13:02,862 - mmcls - INFO - Epoch [5][2400/3125]	lr: 1.000e-01, eta: 8:57:23, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7719
2023-02-07 07:13:08,105 - mmcls - INFO - Epoch [5][2500/3125]	lr: 1.000e-01, eta: 8:57:16, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7808
2023-02-07 07:13:13,301 - mmcls - INFO - Epoch [5][2600/3125]	lr: 1.000e-01, eta: 8:57:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7772
2023-02-07 07:13:18,493 - mmcls - INFO - Epoch [5][2700/3125]	lr: 1.000e-01, eta: 8:56:58, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7978
2023-02-07 07:13:23,688 - mmcls - INFO - Epoch [5][2800/3125]	lr: 1.000e-01, eta: 8:56:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7888
2023-02-07 07:13:28,882 - mmcls - INFO - Epoch [5][2900/3125]	lr: 1.000e-01, eta: 8:56:41, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8392
2023-02-07 07:13:34,073 - mmcls - INFO - Epoch [5][3000/3125]	lr: 1.000e-01, eta: 8:56:32, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7980
2023-02-07 07:13:39,264 - mmcls - INFO - Epoch [5][3100/3125]	lr: 1.000e-01, eta: 8:56:23, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8021
2023-02-07 07:13:40,566 - mmcls - INFO - Saving checkpoint at 5 epochs
2023-02-07 07:13:50,440 - mmcls - INFO - Epoch(val) [5][625]	accuracy_top-1: 68.4500, accuracy_top-5: 97.6100
2023-02-07 07:13:57,679 - mmcls - INFO - Epoch [6][100/3125]	lr: 1.000e-01, eta: 8:56:41, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.7637
2023-02-07 07:14:02,887 - mmcls - INFO - Epoch [6][200/3125]	lr: 1.000e-01, eta: 8:56:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7148
2023-02-07 07:14:08,087 - mmcls - INFO - Epoch [6][300/3125]	lr: 1.000e-01, eta: 8:56:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7970
2023-02-07 07:14:13,291 - mmcls - INFO - Epoch [6][400/3125]	lr: 1.000e-01, eta: 8:56:16, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8054
2023-02-07 07:14:18,490 - mmcls - INFO - Epoch [6][500/3125]	lr: 1.000e-01, eta: 8:56:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8422
2023-02-07 07:14:23,692 - mmcls - INFO - Epoch [6][600/3125]	lr: 1.000e-01, eta: 8:55:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.8164
2023-02-07 07:14:28,890 - mmcls - INFO - Epoch [6][700/3125]	lr: 1.000e-01, eta: 8:55:50, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7510
2023-02-07 07:14:34,090 - mmcls - INFO - Epoch [6][800/3125]	lr: 1.000e-01, eta: 8:55:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7566
2023-02-07 07:14:39,288 - mmcls - INFO - Epoch [6][900/3125]	lr: 1.000e-01, eta: 8:55:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7570
2023-02-07 07:14:44,483 - mmcls - INFO - Epoch [6][1000/3125]	lr: 1.000e-01, eta: 8:55:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7721
2023-02-07 07:14:49,675 - mmcls - INFO - Epoch [6][1100/3125]	lr: 1.000e-01, eta: 8:55:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7265
2023-02-07 07:14:54,874 - mmcls - INFO - Epoch [6][1200/3125]	lr: 1.000e-01, eta: 8:55:08, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7598
2023-02-07 07:15:00,068 - mmcls - INFO - Epoch [6][1300/3125]	lr: 1.000e-01, eta: 8:55:00, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7627
2023-02-07 07:15:05,278 - mmcls - INFO - Epoch [6][1400/3125]	lr: 1.000e-01, eta: 8:54:52, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7378
2023-02-07 07:15:10,482 - mmcls - INFO - Epoch [6][1500/3125]	lr: 1.000e-01, eta: 8:54:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7270
2023-02-07 07:15:15,682 - mmcls - INFO - Epoch [6][1600/3125]	lr: 1.000e-01, eta: 8:54:36, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7539
2023-02-07 07:15:20,878 - mmcls - INFO - Epoch [6][1700/3125]	lr: 1.000e-01, eta: 8:54:28, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7537
2023-02-07 07:15:26,068 - mmcls - INFO - Epoch [6][1800/3125]	lr: 1.000e-01, eta: 8:54:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7443
2023-02-07 07:15:31,265 - mmcls - INFO - Epoch [6][1900/3125]	lr: 1.000e-01, eta: 8:54:12, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7762
2023-02-07 07:15:36,463 - mmcls - INFO - Epoch [6][2000/3125]	lr: 1.000e-01, eta: 8:54:04, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7216
2023-02-07 07:15:41,658 - mmcls - INFO - Epoch [6][2100/3125]	lr: 1.000e-01, eta: 8:53:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7693
2023-02-07 07:15:46,858 - mmcls - INFO - Epoch [6][2200/3125]	lr: 1.000e-01, eta: 8:53:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7331
2023-02-07 07:15:52,060 - mmcls - INFO - Epoch [6][2300/3125]	lr: 1.000e-01, eta: 8:53:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7048
2023-02-07 07:15:57,301 - mmcls - INFO - Epoch [6][2400/3125]	lr: 1.000e-01, eta: 8:53:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7516
2023-02-07 07:16:02,540 - mmcls - INFO - Epoch [6][2500/3125]	lr: 1.000e-01, eta: 8:53:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7165
2023-02-07 07:16:07,747 - mmcls - INFO - Epoch [6][2600/3125]	lr: 1.000e-01, eta: 8:53:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7234
2023-02-07 07:16:12,973 - mmcls - INFO - Epoch [6][2700/3125]	lr: 1.000e-01, eta: 8:53:13, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7128
2023-02-07 07:16:18,201 - mmcls - INFO - Epoch [6][2800/3125]	lr: 1.000e-01, eta: 8:53:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7306
2023-02-07 07:16:23,425 - mmcls - INFO - Epoch [6][2900/3125]	lr: 1.000e-01, eta: 8:52:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7080
2023-02-07 07:16:28,695 - mmcls - INFO - Epoch [6][3000/3125]	lr: 1.000e-01, eta: 8:52:54, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7225
2023-02-07 07:16:33,887 - mmcls - INFO - Epoch [6][3100/3125]	lr: 1.000e-01, eta: 8:52:46, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7520
2023-02-07 07:16:35,188 - mmcls - INFO - Saving checkpoint at 6 epochs
2023-02-07 07:16:45,376 - mmcls - INFO - Epoch(val) [6][625]	accuracy_top-1: 74.3600, accuracy_top-5: 98.4100
2023-02-07 07:16:52,670 - mmcls - INFO - Epoch [7][100/3125]	lr: 1.000e-01, eta: 8:53:02, time: 0.073, data_time: 0.020, memory: 1110, loss: 0.7251
2023-02-07 07:16:57,924 - mmcls - INFO - Epoch [7][200/3125]	lr: 1.000e-01, eta: 8:52:56, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7850
2023-02-07 07:17:03,186 - mmcls - INFO - Epoch [7][300/3125]	lr: 1.000e-01, eta: 8:52:50, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7506
2023-02-07 07:17:08,438 - mmcls - INFO - Epoch [7][400/3125]	lr: 1.000e-01, eta: 8:52:44, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7014
2023-02-07 07:17:13,688 - mmcls - INFO - Epoch [7][500/3125]	lr: 1.000e-01, eta: 8:52:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7081
2023-02-07 07:17:18,951 - mmcls - INFO - Epoch [7][600/3125]	lr: 1.000e-01, eta: 8:52:32, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7316
2023-02-07 07:17:24,216 - mmcls - INFO - Epoch [7][700/3125]	lr: 1.000e-01, eta: 8:52:27, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6860
2023-02-07 07:17:29,398 - mmcls - INFO - Epoch [7][800/3125]	lr: 1.000e-01, eta: 8:52:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7525
2023-02-07 07:17:34,596 - mmcls - INFO - Epoch [7][900/3125]	lr: 1.000e-01, eta: 8:52:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6653
2023-02-07 07:17:39,792 - mmcls - INFO - Epoch [7][1000/3125]	lr: 1.000e-01, eta: 8:52:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7133
2023-02-07 07:17:44,993 - mmcls - INFO - Epoch [7][1100/3125]	lr: 1.000e-01, eta: 8:51:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7375
2023-02-07 07:17:50,192 - mmcls - INFO - Epoch [7][1200/3125]	lr: 1.000e-01, eta: 8:51:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7112
2023-02-07 07:17:55,387 - mmcls - INFO - Epoch [7][1300/3125]	lr: 1.000e-01, eta: 8:51:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7603
2023-02-07 07:18:00,567 - mmcls - INFO - Epoch [7][1400/3125]	lr: 1.000e-01, eta: 8:51:32, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7208
2023-02-07 07:18:05,748 - mmcls - INFO - Epoch [7][1500/3125]	lr: 1.000e-01, eta: 8:51:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6886
2023-02-07 07:18:10,938 - mmcls - INFO - Epoch [7][1600/3125]	lr: 1.000e-01, eta: 8:51:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7531
2023-02-07 07:18:16,124 - mmcls - INFO - Epoch [7][1700/3125]	lr: 1.000e-01, eta: 8:51:09, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7348
2023-02-07 07:18:21,342 - mmcls - INFO - Epoch [7][1800/3125]	lr: 1.000e-01, eta: 8:51:02, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7523
2023-02-07 07:18:26,540 - mmcls - INFO - Epoch [7][1900/3125]	lr: 1.000e-01, eta: 8:50:54, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7279
2023-02-07 07:18:31,740 - mmcls - INFO - Epoch [7][2000/3125]	lr: 1.000e-01, eta: 8:50:47, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6863
2023-02-07 07:18:36,945 - mmcls - INFO - Epoch [7][2100/3125]	lr: 1.000e-01, eta: 8:50:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7641
2023-02-07 07:18:42,146 - mmcls - INFO - Epoch [7][2200/3125]	lr: 1.000e-01, eta: 8:50:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7932
2023-02-07 07:18:47,340 - mmcls - INFO - Epoch [7][2300/3125]	lr: 1.000e-01, eta: 8:50:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7038
2023-02-07 07:18:52,535 - mmcls - INFO - Epoch [7][2400/3125]	lr: 1.000e-01, eta: 8:50:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6460
2023-02-07 07:18:57,736 - mmcls - INFO - Epoch [7][2500/3125]	lr: 1.000e-01, eta: 8:50:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7101
2023-02-07 07:19:02,937 - mmcls - INFO - Epoch [7][2600/3125]	lr: 1.000e-01, eta: 8:50:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6615
2023-02-07 07:19:08,102 - mmcls - INFO - Epoch [7][2700/3125]	lr: 1.000e-01, eta: 8:49:55, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6858
2023-02-07 07:19:13,307 - mmcls - INFO - Epoch [7][2800/3125]	lr: 1.000e-01, eta: 8:49:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7113
2023-02-07 07:19:18,511 - mmcls - INFO - Epoch [7][2900/3125]	lr: 1.000e-01, eta: 8:49:41, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6636
2023-02-07 07:19:23,708 - mmcls - INFO - Epoch [7][3000/3125]	lr: 1.000e-01, eta: 8:49:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7409
2023-02-07 07:19:28,909 - mmcls - INFO - Epoch [7][3100/3125]	lr: 1.000e-01, eta: 8:49:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7523
2023-02-07 07:19:30,232 - mmcls - INFO - Saving checkpoint at 7 epochs
2023-02-07 07:19:40,323 - mmcls - INFO - Epoch(val) [7][625]	accuracy_top-1: 79.0100, accuracy_top-5: 98.8000
2023-02-07 07:19:47,526 - mmcls - INFO - Epoch [8][100/3125]	lr: 1.000e-01, eta: 8:49:37, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.6795
2023-02-07 07:19:52,771 - mmcls - INFO - Epoch [8][200/3125]	lr: 1.000e-01, eta: 8:49:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7043
2023-02-07 07:19:58,033 - mmcls - INFO - Epoch [8][300/3125]	lr: 1.000e-01, eta: 8:49:26, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7020
2023-02-07 07:20:03,291 - mmcls - INFO - Epoch [8][400/3125]	lr: 1.000e-01, eta: 8:49:20, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6786
2023-02-07 07:20:08,556 - mmcls - INFO - Epoch [8][500/3125]	lr: 1.000e-01, eta: 8:49:15, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6730
2023-02-07 07:20:13,822 - mmcls - INFO - Epoch [8][600/3125]	lr: 1.000e-01, eta: 8:49:09, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6883
2023-02-07 07:20:19,086 - mmcls - INFO - Epoch [8][700/3125]	lr: 1.000e-01, eta: 8:49:04, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6798
2023-02-07 07:20:24,365 - mmcls - INFO - Epoch [8][800/3125]	lr: 1.000e-01, eta: 8:48:59, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7165
2023-02-07 07:20:29,651 - mmcls - INFO - Epoch [8][900/3125]	lr: 1.000e-01, eta: 8:48:54, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6556
2023-02-07 07:20:34,844 - mmcls - INFO - Epoch [8][1000/3125]	lr: 1.000e-01, eta: 8:48:47, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6892
2023-02-07 07:20:40,035 - mmcls - INFO - Epoch [8][1100/3125]	lr: 1.000e-01, eta: 8:48:39, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6931
2023-02-07 07:20:45,232 - mmcls - INFO - Epoch [8][1200/3125]	lr: 1.000e-01, eta: 8:48:32, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6600
2023-02-07 07:20:50,432 - mmcls - INFO - Epoch [8][1300/3125]	lr: 1.000e-01, eta: 8:48:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7531
2023-02-07 07:20:55,689 - mmcls - INFO - Epoch [8][1400/3125]	lr: 1.000e-01, eta: 8:48:20, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6970
2023-02-07 07:21:00,948 - mmcls - INFO - Epoch [8][1500/3125]	lr: 1.000e-01, eta: 8:48:14, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7038
2023-02-07 07:21:06,215 - mmcls - INFO - Epoch [8][1600/3125]	lr: 1.000e-01, eta: 8:48:09, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6810
2023-02-07 07:21:11,461 - mmcls - INFO - Epoch [8][1700/3125]	lr: 1.000e-01, eta: 8:48:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7237
2023-02-07 07:21:16,704 - mmcls - INFO - Epoch [8][1800/3125]	lr: 1.000e-01, eta: 8:47:57, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7031
2023-02-07 07:21:21,980 - mmcls - INFO - Epoch [8][1900/3125]	lr: 1.000e-01, eta: 8:47:52, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7015
2023-02-07 07:21:27,253 - mmcls - INFO - Epoch [8][2000/3125]	lr: 1.000e-01, eta: 8:47:47, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6713
2023-02-07 07:21:32,520 - mmcls - INFO - Epoch [8][2100/3125]	lr: 1.000e-01, eta: 8:47:41, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6288
2023-02-07 07:21:37,786 - mmcls - INFO - Epoch [8][2200/3125]	lr: 1.000e-01, eta: 8:47:36, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.7064
2023-02-07 07:21:43,036 - mmcls - INFO - Epoch [8][2300/3125]	lr: 1.000e-01, eta: 8:47:30, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6837
2023-02-07 07:21:48,226 - mmcls - INFO - Epoch [8][2400/3125]	lr: 1.000e-01, eta: 8:47:23, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7080
2023-02-07 07:21:53,435 - mmcls - INFO - Epoch [8][2500/3125]	lr: 1.000e-01, eta: 8:47:16, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6712
2023-02-07 07:21:58,678 - mmcls - INFO - Epoch [8][2600/3125]	lr: 1.000e-01, eta: 8:47:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7190
2023-02-07 07:22:03,879 - mmcls - INFO - Epoch [8][2700/3125]	lr: 1.000e-01, eta: 8:47:04, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7432
2023-02-07 07:22:09,083 - mmcls - INFO - Epoch [8][2800/3125]	lr: 1.000e-01, eta: 8:46:57, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7554
2023-02-07 07:22:14,291 - mmcls - INFO - Epoch [8][2900/3125]	lr: 1.000e-01, eta: 8:46:50, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6728
2023-02-07 07:22:19,501 - mmcls - INFO - Epoch [8][3000/3125]	lr: 1.000e-01, eta: 8:46:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7143
2023-02-07 07:22:24,706 - mmcls - INFO - Epoch [8][3100/3125]	lr: 1.000e-01, eta: 8:46:37, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6718
2023-02-07 07:22:26,005 - mmcls - INFO - Saving checkpoint at 8 epochs
2023-02-07 07:22:36,206 - mmcls - INFO - Epoch(val) [8][625]	accuracy_top-1: 75.3000, accuracy_top-5: 98.0000
2023-02-07 07:22:43,415 - mmcls - INFO - Epoch [9][100/3125]	lr: 1.000e-01, eta: 8:46:45, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.6585
2023-02-07 07:22:48,619 - mmcls - INFO - Epoch [9][200/3125]	lr: 1.000e-01, eta: 8:46:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6375
2023-02-07 07:22:53,819 - mmcls - INFO - Epoch [9][300/3125]	lr: 1.000e-01, eta: 8:46:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6489
2023-02-07 07:22:59,019 - mmcls - INFO - Epoch [9][400/3125]	lr: 1.000e-01, eta: 8:46:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6996
2023-02-07 07:23:04,213 - mmcls - INFO - Epoch [9][500/3125]	lr: 1.000e-01, eta: 8:46:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6409
2023-02-07 07:23:09,396 - mmcls - INFO - Epoch [9][600/3125]	lr: 1.000e-01, eta: 8:46:10, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6839
2023-02-07 07:23:14,580 - mmcls - INFO - Epoch [9][700/3125]	lr: 1.000e-01, eta: 8:46:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7219
2023-02-07 07:23:19,768 - mmcls - INFO - Epoch [9][800/3125]	lr: 1.000e-01, eta: 8:45:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6317
2023-02-07 07:23:24,951 - mmcls - INFO - Epoch [9][900/3125]	lr: 1.000e-01, eta: 8:45:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6619
2023-02-07 07:23:30,133 - mmcls - INFO - Epoch [9][1000/3125]	lr: 1.000e-01, eta: 8:45:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7655
2023-02-07 07:23:35,312 - mmcls - INFO - Epoch [9][1100/3125]	lr: 1.000e-01, eta: 8:45:34, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6856
2023-02-07 07:23:40,494 - mmcls - INFO - Epoch [9][1200/3125]	lr: 1.000e-01, eta: 8:45:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6901
2023-02-07 07:23:45,676 - mmcls - INFO - Epoch [9][1300/3125]	lr: 1.000e-01, eta: 8:45:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6898
2023-02-07 07:23:50,859 - mmcls - INFO - Epoch [9][1400/3125]	lr: 1.000e-01, eta: 8:45:13, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6609
2023-02-07 07:23:56,042 - mmcls - INFO - Epoch [9][1500/3125]	lr: 1.000e-01, eta: 8:45:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6824
2023-02-07 07:24:01,225 - mmcls - INFO - Epoch [9][1600/3125]	lr: 1.000e-01, eta: 8:44:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6918
2023-02-07 07:24:06,413 - mmcls - INFO - Epoch [9][1700/3125]	lr: 1.000e-01, eta: 8:44:52, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6883
2023-02-07 07:24:11,598 - mmcls - INFO - Epoch [9][1800/3125]	lr: 1.000e-01, eta: 8:44:45, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6956
2023-02-07 07:24:16,782 - mmcls - INFO - Epoch [9][1900/3125]	lr: 1.000e-01, eta: 8:44:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6489
2023-02-07 07:24:21,965 - mmcls - INFO - Epoch [9][2000/3125]	lr: 1.000e-01, eta: 8:44:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6215
2023-02-07 07:24:27,147 - mmcls - INFO - Epoch [9][2100/3125]	lr: 1.000e-01, eta: 8:44:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7073
2023-02-07 07:24:32,331 - mmcls - INFO - Epoch [9][2200/3125]	lr: 1.000e-01, eta: 8:44:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6761
2023-02-07 07:24:37,521 - mmcls - INFO - Epoch [9][2300/3125]	lr: 1.000e-01, eta: 8:44:10, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6798
2023-02-07 07:24:42,709 - mmcls - INFO - Epoch [9][2400/3125]	lr: 1.000e-01, eta: 8:44:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6678
2023-02-07 07:24:47,898 - mmcls - INFO - Epoch [9][2500/3125]	lr: 1.000e-01, eta: 8:43:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6518
2023-02-07 07:24:53,081 - mmcls - INFO - Epoch [9][2600/3125]	lr: 1.000e-01, eta: 8:43:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6710
2023-02-07 07:24:58,261 - mmcls - INFO - Epoch [9][2700/3125]	lr: 1.000e-01, eta: 8:43:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6815
2023-02-07 07:25:03,444 - mmcls - INFO - Epoch [9][2800/3125]	lr: 1.000e-01, eta: 8:43:35, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6515
2023-02-07 07:25:08,626 - mmcls - INFO - Epoch [9][2900/3125]	lr: 1.000e-01, eta: 8:43:28, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6886
2023-02-07 07:25:13,812 - mmcls - INFO - Epoch [9][3000/3125]	lr: 1.000e-01, eta: 8:43:21, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7117
2023-02-07 07:25:19,003 - mmcls - INFO - Epoch [9][3100/3125]	lr: 1.000e-01, eta: 8:43:15, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6685
2023-02-07 07:25:20,302 - mmcls - INFO - Saving checkpoint at 9 epochs
2023-02-07 07:25:30,489 - mmcls - INFO - Epoch(val) [9][625]	accuracy_top-1: 78.0500, accuracy_top-5: 98.7700
2023-02-07 07:25:37,685 - mmcls - INFO - Epoch [10][100/3125]	lr: 1.000e-01, eta: 8:43:21, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.6645
2023-02-07 07:25:42,924 - mmcls - INFO - Epoch [10][200/3125]	lr: 1.000e-01, eta: 8:43:15, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6350
2023-02-07 07:25:48,199 - mmcls - INFO - Epoch [10][300/3125]	lr: 1.000e-01, eta: 8:43:10, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6481
2023-02-07 07:25:53,446 - mmcls - INFO - Epoch [10][400/3125]	lr: 1.000e-01, eta: 8:43:05, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6031
2023-02-07 07:25:58,634 - mmcls - INFO - Epoch [10][500/3125]	lr: 1.000e-01, eta: 8:42:58, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6760
2023-02-07 07:26:03,824 - mmcls - INFO - Epoch [10][600/3125]	lr: 1.000e-01, eta: 8:42:51, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6709
2023-02-07 07:26:09,029 - mmcls - INFO - Epoch [10][700/3125]	lr: 1.000e-01, eta: 8:42:45, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6577
2023-02-07 07:26:14,222 - mmcls - INFO - Epoch [10][800/3125]	lr: 1.000e-01, eta: 8:42:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6220
2023-02-07 07:26:19,415 - mmcls - INFO - Epoch [10][900/3125]	lr: 1.000e-01, eta: 8:42:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6410
2023-02-07 07:26:24,602 - mmcls - INFO - Epoch [10][1000/3125]	lr: 1.000e-01, eta: 8:42:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6627
2023-02-07 07:26:29,791 - mmcls - INFO - Epoch [10][1100/3125]	lr: 1.000e-01, eta: 8:42:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6028
2023-02-07 07:26:34,983 - mmcls - INFO - Epoch [10][1200/3125]	lr: 1.000e-01, eta: 8:42:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6286
2023-02-07 07:26:40,174 - mmcls - INFO - Epoch [10][1300/3125]	lr: 1.000e-01, eta: 8:42:05, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6675
2023-02-07 07:26:45,368 - mmcls - INFO - Epoch [10][1400/3125]	lr: 1.000e-01, eta: 8:41:58, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6548
2023-02-07 07:26:50,560 - mmcls - INFO - Epoch [10][1500/3125]	lr: 1.000e-01, eta: 8:41:51, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6490
2023-02-07 07:26:55,758 - mmcls - INFO - Epoch [10][1600/3125]	lr: 1.000e-01, eta: 8:41:45, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6880
2023-02-07 07:27:00,959 - mmcls - INFO - Epoch [10][1700/3125]	lr: 1.000e-01, eta: 8:41:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6584
2023-02-07 07:27:06,147 - mmcls - INFO - Epoch [10][1800/3125]	lr: 1.000e-01, eta: 8:41:32, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6435
2023-02-07 07:27:11,343 - mmcls - INFO - Epoch [10][1900/3125]	lr: 1.000e-01, eta: 8:41:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6597
2023-02-07 07:27:16,540 - mmcls - INFO - Epoch [10][2000/3125]	lr: 1.000e-01, eta: 8:41:19, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7031
2023-02-07 07:27:21,740 - mmcls - INFO - Epoch [10][2100/3125]	lr: 1.000e-01, eta: 8:41:12, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6334
2023-02-07 07:27:26,943 - mmcls - INFO - Epoch [10][2200/3125]	lr: 1.000e-01, eta: 8:41:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6678
2023-02-07 07:27:32,144 - mmcls - INFO - Epoch [10][2300/3125]	lr: 1.000e-01, eta: 8:41:00, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6828
2023-02-07 07:27:37,332 - mmcls - INFO - Epoch [10][2400/3125]	lr: 1.000e-01, eta: 8:40:53, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6590
2023-02-07 07:27:42,517 - mmcls - INFO - Epoch [10][2500/3125]	lr: 1.000e-01, eta: 8:40:46, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6175
2023-02-07 07:27:47,709 - mmcls - INFO - Epoch [10][2600/3125]	lr: 1.000e-01, eta: 8:40:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6093
2023-02-07 07:27:52,899 - mmcls - INFO - Epoch [10][2700/3125]	lr: 1.000e-01, eta: 8:40:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6260
2023-02-07 07:27:58,088 - mmcls - INFO - Epoch [10][2800/3125]	lr: 1.000e-01, eta: 8:40:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6626
2023-02-07 07:28:03,276 - mmcls - INFO - Epoch [10][2900/3125]	lr: 1.000e-01, eta: 8:40:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.7142
2023-02-07 07:28:08,466 - mmcls - INFO - Epoch [10][3000/3125]	lr: 1.000e-01, eta: 8:40:14, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6523
2023-02-07 07:28:13,656 - mmcls - INFO - Epoch [10][3100/3125]	lr: 1.000e-01, eta: 8:40:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6659
2023-02-07 07:28:14,965 - mmcls - INFO - Saving checkpoint at 10 epochs
2023-02-07 07:28:25,460 - mmcls - INFO - Epoch(val) [10][625]	accuracy_top-1: 78.4100, accuracy_top-5: 99.0400
2023-02-07 07:28:32,717 - mmcls - INFO - Epoch [11][100/3125]	lr: 1.000e-01, eta: 8:40:14, time: 0.073, data_time: 0.020, memory: 1110, loss: 0.6071
2023-02-07 07:28:37,922 - mmcls - INFO - Epoch [11][200/3125]	lr: 1.000e-01, eta: 8:40:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6650
2023-02-07 07:28:43,123 - mmcls - INFO - Epoch [11][300/3125]	lr: 1.000e-01, eta: 8:40:01, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6259
2023-02-07 07:28:48,335 - mmcls - INFO - Epoch [11][400/3125]	lr: 1.000e-01, eta: 8:39:55, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6777
2023-02-07 07:28:53,551 - mmcls - INFO - Epoch [11][500/3125]	lr: 1.000e-01, eta: 8:39:49, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6441
2023-02-07 07:28:58,751 - mmcls - INFO - Epoch [11][600/3125]	lr: 1.000e-01, eta: 8:39:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6414
2023-02-07 07:29:03,957 - mmcls - INFO - Epoch [11][700/3125]	lr: 1.000e-01, eta: 8:39:36, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6040
2023-02-07 07:29:09,161 - mmcls - INFO - Epoch [11][800/3125]	lr: 1.000e-01, eta: 8:39:30, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6525
2023-02-07 07:29:14,368 - mmcls - INFO - Epoch [11][900/3125]	lr: 1.000e-01, eta: 8:39:24, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6264
2023-02-07 07:29:19,595 - mmcls - INFO - Epoch [11][1000/3125]	lr: 1.000e-01, eta: 8:39:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6448
2023-02-07 07:29:24,853 - mmcls - INFO - Epoch [11][1100/3125]	lr: 1.000e-01, eta: 8:39:13, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6246
2023-02-07 07:29:30,105 - mmcls - INFO - Epoch [11][1200/3125]	lr: 1.000e-01, eta: 8:39:07, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6137
2023-02-07 07:29:35,320 - mmcls - INFO - Epoch [11][1300/3125]	lr: 1.000e-01, eta: 8:39:01, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6336
2023-02-07 07:29:40,554 - mmcls - INFO - Epoch [11][1400/3125]	lr: 1.000e-01, eta: 8:38:56, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6439
2023-02-07 07:29:45,811 - mmcls - INFO - Epoch [11][1500/3125]	lr: 1.000e-01, eta: 8:38:50, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6885
2023-02-07 07:29:50,998 - mmcls - INFO - Epoch [11][1600/3125]	lr: 1.000e-01, eta: 8:38:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6779
2023-02-07 07:29:56,188 - mmcls - INFO - Epoch [11][1700/3125]	lr: 1.000e-01, eta: 8:38:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6440
2023-02-07 07:30:01,376 - mmcls - INFO - Epoch [11][1800/3125]	lr: 1.000e-01, eta: 8:38:31, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6540
2023-02-07 07:30:06,565 - mmcls - INFO - Epoch [11][1900/3125]	lr: 1.000e-01, eta: 8:38:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6502
2023-02-07 07:30:11,755 - mmcls - INFO - Epoch [11][2000/3125]	lr: 1.000e-01, eta: 8:38:18, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6421
2023-02-07 07:30:16,942 - mmcls - INFO - Epoch [11][2100/3125]	lr: 1.000e-01, eta: 8:38:12, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6326
2023-02-07 07:30:22,132 - mmcls - INFO - Epoch [11][2200/3125]	lr: 1.000e-01, eta: 8:38:05, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6749
2023-02-07 07:30:27,324 - mmcls - INFO - Epoch [11][2300/3125]	lr: 1.000e-01, eta: 8:37:59, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6557
2023-02-07 07:30:32,516 - mmcls - INFO - Epoch [11][2400/3125]	lr: 1.000e-01, eta: 8:37:53, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6392
2023-02-07 07:30:37,708 - mmcls - INFO - Epoch [11][2500/3125]	lr: 1.000e-01, eta: 8:37:46, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6709
2023-02-07 07:30:42,896 - mmcls - INFO - Epoch [11][2600/3125]	lr: 1.000e-01, eta: 8:37:40, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6701
2023-02-07 07:30:48,085 - mmcls - INFO - Epoch [11][2700/3125]	lr: 1.000e-01, eta: 8:37:33, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6150
2023-02-07 07:30:53,270 - mmcls - INFO - Epoch [11][2800/3125]	lr: 1.000e-01, eta: 8:37:27, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6084
2023-02-07 07:30:58,455 - mmcls - INFO - Epoch [11][2900/3125]	lr: 1.000e-01, eta: 8:37:20, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6600
2023-02-07 07:31:03,637 - mmcls - INFO - Epoch [11][3000/3125]	lr: 1.000e-01, eta: 8:37:14, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6172
2023-02-07 07:31:08,819 - mmcls - INFO - Epoch [11][3100/3125]	lr: 1.000e-01, eta: 8:37:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6455
2023-02-07 07:31:10,129 - mmcls - INFO - Saving checkpoint at 11 epochs
2023-02-07 07:31:20,449 - mmcls - INFO - Epoch(val) [11][625]	accuracy_top-1: 74.5000, accuracy_top-5: 98.5800
2023-02-07 07:31:27,696 - mmcls - INFO - Epoch [12][100/3125]	lr: 1.000e-01, eta: 8:37:13, time: 0.072, data_time: 0.020, memory: 1110, loss: 0.6094
2023-02-07 07:31:32,901 - mmcls - INFO - Epoch [12][200/3125]	lr: 1.000e-01, eta: 8:37:06, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6533
2023-02-07 07:31:38,102 - mmcls - INFO - Epoch [12][300/3125]	lr: 1.000e-01, eta: 8:37:00, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6281
2023-02-07 07:31:43,295 - mmcls - INFO - Epoch [12][400/3125]	lr: 1.000e-01, eta: 8:36:54, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6320
2023-02-07 07:31:48,488 - mmcls - INFO - Epoch [12][500/3125]	lr: 1.000e-01, eta: 8:36:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6879
2023-02-07 07:31:53,738 - mmcls - INFO - Epoch [12][600/3125]	lr: 1.000e-01, eta: 8:36:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6569
2023-02-07 07:31:59,013 - mmcls - INFO - Epoch [12][700/3125]	lr: 1.000e-01, eta: 8:36:37, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6620
2023-02-07 07:32:04,278 - mmcls - INFO - Epoch [12][800/3125]	lr: 1.000e-01, eta: 8:36:32, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6156
2023-02-07 07:32:09,533 - mmcls - INFO - Epoch [12][900/3125]	lr: 1.000e-01, eta: 8:36:27, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6142
2023-02-07 07:32:14,793 - mmcls - INFO - Epoch [12][1000/3125]	lr: 1.000e-01, eta: 8:36:22, time: 0.053, data_time: 0.000, memory: 1110, loss: 0.6541
2023-02-07 07:32:19,958 - mmcls - INFO - Epoch [12][1100/3125]	lr: 1.000e-01, eta: 8:36:15, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6308
2023-02-07 07:32:25,156 - mmcls - INFO - Epoch [12][1200/3125]	lr: 1.000e-01, eta: 8:36:09, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6429
2023-02-07 07:32:30,376 - mmcls - INFO - Epoch [12][1300/3125]	lr: 1.000e-01, eta: 8:36:03, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6418
2023-02-07 07:32:35,568 - mmcls - INFO - Epoch [12][1400/3125]	lr: 1.000e-01, eta: 8:35:57, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.5837
2023-02-07 07:32:40,761 - mmcls - INFO - Epoch [12][1500/3125]	lr: 1.000e-01, eta: 8:35:51, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6376
2023-02-07 07:32:45,952 - mmcls - INFO - Epoch [12][1600/3125]	lr: 1.000e-01, eta: 8:35:44, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6239
2023-02-07 07:32:51,145 - mmcls - INFO - Epoch [12][1700/3125]	lr: 1.000e-01, eta: 8:35:38, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6219
2023-02-07 07:32:56,336 - mmcls - INFO - Epoch [12][1800/3125]	lr: 1.000e-01, eta: 8:35:32, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6207
2023-02-07 07:33:01,525 - mmcls - INFO - Epoch [12][1900/3125]	lr: 1.000e-01, eta: 8:35:25, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6727
2023-02-07 07:33:06,719 - mmcls - INFO - Epoch [12][2000/3125]	lr: 1.000e-01, eta: 8:35:19, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.5939
2023-02-07 07:33:11,909 - mmcls - INFO - Epoch [12][2100/3125]	lr: 1.000e-01, eta: 8:35:13, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6629
2023-02-07 07:33:17,101 - mmcls - INFO - Epoch [12][2200/3125]	lr: 1.000e-01, eta: 8:35:07, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.5767
2023-02-07 07:33:22,284 - mmcls - INFO - Epoch [12][2300/3125]	lr: 1.000e-01, eta: 8:35:00, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6481
2023-02-07 07:33:27,477 - mmcls - INFO - Epoch [12][2400/3125]	lr: 1.000e-01, eta: 8:34:54, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6069
2023-02-07 07:33:32,675 - mmcls - INFO - Epoch [12][2500/3125]	lr: 1.000e-01, eta: 8:34:48, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6522
2023-02-07 07:33:37,864 - mmcls - INFO - Epoch [12][2600/3125]	lr: 1.000e-01, eta: 8:34:42, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.5835
2023-02-07 07:33:43,060 - mmcls - INFO - Epoch [12][2700/3125]	lr: 1.000e-01, eta: 8:34:36, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6073
2023-02-07 07:33:48,248 - mmcls - INFO - Epoch [12][2800/3125]	lr: 1.000e-01, eta: 8:34:29, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6308
2023-02-07 07:33:53,436 - mmcls - INFO - Epoch [12][2900/3125]	lr: 1.000e-01, eta: 8:34:23, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6903
2023-02-07 07:33:58,623 - mmcls - INFO - Epoch [12][3000/3125]	lr: 1.000e-01, eta: 8:34:17, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6242
2023-02-07 07:34:03,813 - mmcls - INFO - Epoch [12][3100/3125]	lr: 1.000e-01, eta: 8:34:11, time: 0.052, data_time: 0.000, memory: 1110, loss: 0.6509
2023-02-07 07:34:05,113 - mmcls - INFO - Saving checkpoint at 12 epochs
